import warnings
from collections import deque
from typing import Tuple
import torch
from PIL import Image
from softadapt.base._softadapt_base_class import SoftAdaptBase
from torch import Tensor
import torch.nn as nn
import torch.nn.functional as F
from softadapt import LossWeightedSoftAdapt, SoftAdapt, NormalizedSoftAdapt
from torch.autograd import Variable
import numpy as np
from math import exp
import wandb
from torch.nn import Module, MSELoss
from torchvision import transforms
from torchvision.transforms import v2

# from libraries.pytorch_iou import IOU as IoU0
# from pytorch_msssim import ssim as ssim1
from scipy.optimize import minimize
import kornia.contrib as kc

# ---------- æ”¹è¿›æ•°å€¼ä¸ç¨³å®š ----------
class IOULoss(nn.Module):
    def __init__(self, soft=False, alpha=False, size_average=True, epsilon=1e-8):
        super(IOULoss, self).__init__()
        self.soft = soft
        self.alpha = alpha
        self.size_average = size_average
        self.epsilon = epsilon

    def forward(self, pred, target):
        return _iou_loss(pred, target, self.soft, self.alpha, self.size_average, self.epsilon)


def _iou_loss(pred, target, soft=False, alpha=False, size_average=True, epsilon=1e-8):
    if soft:
        pred = torch.sigmoid(pred)
    if alpha:
        pred_sum = pred.sum(dim=(1, 2, 3))
        target_sum = target.sum(dim=(1, 2, 3))
        dis = torch.pow((pred_sum - target_sum) / 2, 2)
        alpha = (torch.min(pred_sum, target_sum) + dis + epsilon) / (torch.max(pred_sum, target_sum) + dis + epsilon)
    else:
        alpha = 1

    intersection = (pred * target).sum(dim=(1, 2, 3))  # Intersection over the batch
    union = (pred + target).sum(dim=(1, 2, 3)) - intersection  # Union over the batch

    iou = (intersection + epsilon) / (union + epsilon)  # Compute IoU

    iou_loss = 1 - alpha * iou  # IoU loss is 1 - IoU

    if size_average:
        return iou_loss.mean()  # Return average loss over the batch
    else:
        return iou_loss.sum()  # Return sum loss over the batch


# MENet Soft IOU
def soft_iou(preds, target):
    pred = torch.sigmoid(preds)

    inter = torch.sum(target * pred, dim=(1, 2, 3))
    union = torch.sum(target, dim=(1, 2, 3)) + torch.sum(pred, dim=(1, 2, 3)) - inter
    soft_iou_loss = 1 - ((inter + 1) / (union + 1)).mean()
    return soft_iou_loss


class RegionLoss(nn.Module):
    def __init__(self, k1=0.01, k2=0.03, l=1, epsilon=1e-10, sig=False, log=False, size_average=True):
        super(RegionLoss, self).__init__()
        self.k1, self.k2, self.k3 = k1, k2, k2/2
        self.l, self.epsilon = l, epsilon
        self.sig = sig
        self.log, self.size_average = log, size_average
        self.alpha = 1
        self.beta = 1
        self.gamma = 1

    def centroid(self, gt):
        b, c, h, w = gt.shape
        area_object = gt.sum(dim=(2, 3))  # Shape (B, C)

        safe_area = area_object + self.epsilon * (area_object == 0).float()     # æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤

        row_ids = torch.arange(h, device=gt.device).view(1, 1, h, 1).expand(b, c, h, w)
        col_ids = torch.arange(w, device=gt.device).view(1, 1, 1, w).expand(b, c, h, w)

        x = (gt * col_ids).sum(dim=(2, 3)) / safe_area
        y = (gt * row_ids).sum(dim=(2, 3)) / safe_area

        return x.round().long().clamp(0, w - 1), y.round().long().clamp(0, h - 1)

    def img2region(self, pred, gt, centroid):
        x, y = centroid  # x, y shape (B, C)
        b, c, h, w = gt.shape
        area_total = h * w

        x = x.view(b, c, 1, 1)
        y = y.view(b, c, 1, 1)

        rows = torch.arange(h, device=gt.device).view(1, 1, h, 1).expand(b, c, h, w)
        cols = torch.arange(w, device=gt.device).view(1, 1, 1, w).expand(b, c, h, w)

        mask_LT = (rows < y) & (cols < x)
        mask_RT = (rows < y) & (cols >= x)
        mask_LB = (rows >= y) & (cols < x)
        mask_RB = (rows >= y) & (cols >= x)

        masks = [mask.float() for mask in [mask_LT, mask_RT, mask_LB, mask_RB]]

        w1 = torch.clamp((x * y) / area_total, min=0, max=1)
        w2 = torch.clamp((y * (w - x)) / area_total, min=0, max=1)
        w3 = torch.clamp(((h - y) * x) / area_total, min=0, max=1)
        w4 = torch.clamp(1 - w1 - w2 - w3, min=0, max=1)
        weights = [w1, w2, w3, w4]

        return {"masks": masks, "weights": weights}

    def ssim(self, pred, gt, mask):
        b, c, h, w = gt.shape
        area = mask.sum(dim=(2, 3)) + self.epsilon

        # å‡å€¼è®¡ç®—æ”¹è¿›
        valid_mask = (area > self.epsilon)
        mean_pred = torch.where(valid_mask,
                                (pred * mask).sum(dim=(2, 3)) / area,
                                torch.zeros_like(area))
        mean_gt = torch.where(valid_mask,
                              (gt * mask).sum(dim=(2, 3)) / area,
                              torch.zeros_like(area))

        delta_pred = pred - mean_pred.view(b, c, 1, 1)
        delta_gt = gt - mean_gt.view(b, c, 1, 1)

        # æ–¹å·®åæ–¹å·®è®¡ç®—æ”¹è¿›
        var_pred = (delta_pred ** 2 * mask).sum(dim=(2, 3)) / (area + self.epsilon)
        var_gt = (delta_gt ** 2 * mask).sum(dim=(2, 3)) / (area + self.epsilon)
        cov_xy = (delta_pred * delta_gt * mask).sum(dim=(2, 3)) / (area + self.epsilon)

        # ç¨³å®šæ€§å¢å¼º
        std_pred = torch.sqrt(var_pred + self.epsilon)
        std_gt = torch.sqrt(var_gt + self.epsilon)

        c1 = (self.k1 * self.l) ** 2
        c2 = (self.k2 * self.l) ** 2
        c3 = (self.k3 * self.l) ** 2

        # åˆ†é‡è®¡ç®—æ”¹è¿›
        luma = (2 * mean_pred * mean_gt + c1) / (mean_pred ** 2 + mean_gt ** 2 + c1 + self.epsilon)
        contrast = (2 * std_pred * std_gt + c2) / (var_pred + var_gt + c2 + self.epsilon)
        structure = torch.clamp((cov_xy + c3) / (std_pred * std_gt + c3 + self.epsilon), min=-1.0, max=1.0)

        ssim_val = (luma ** self.alpha) * (contrast ** self.beta) * (structure ** self.gamma)
        return torch.clamp(ssim_val, 0.0, 1.0)

    def forward(self, pred, gt):
        pred = torch.sigmoid(pred) if self.sig else pred
        centroid = self.centroid(gt)
        region = self.img2region(pred, gt, centroid)
        masks, weights = region["masks"], region["weights"]

        total_loss = 0
        for mask, weight in zip(masks, weights):
            # åŒºåŸŸæœ‰æ•ˆæ€§æ£€æŸ¥
            valid = (mask.sum(dim=(1, 2, 3)) > self.epsilon).float()
            ssim_region = self.ssim(pred, gt, mask)

            if self.log:
                ssim_region = torch.clamp(ssim_region, min=self.epsilon, max=1 - self.epsilon)
                loss_term = -torch.log(ssim_region) * valid
            else:
                loss_term = (1 - ssim_region) * valid

            total_loss += (loss_term * weight).sum(dim=1)

        if self.size_average:
            return total_loss.mean()
        else:
            return total_loss.sum()




class DiceLoss(nn.Module):
    def __init__(self, smooth=1):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, pred, target):
        """
        Args:
            pred: ç½‘ç»œè¾“å‡ºçš„æ¦‚ç‡å›¾ï¼Œshapeä¸º[B,1,H,W]æˆ–[B,H,W]ï¼Œå·²ç»è¿‡sigmoid
            target: çœŸå®æ ‡ç­¾ï¼ŒshapeåŒpredï¼Œå€¼ä¸º0æˆ–1
        Returns:
            dice_loss: è®¡ç®—å¾—åˆ°çš„æŸå¤±å€¼
        """
        # ç¡®ä¿è¾“å…¥ç»´åº¦ä¸€è‡´
        pred = pred.view(-1)
        target = target.view(-1)

        # è®¡ç®—äº¤é›†
        intersection = (pred * target).sum()

        # è®¡ç®—diceç³»æ•°
        dice = (2. * intersection + self.smooth) / (
                pred.sum() + target.sum() + self.smooth
        )

        # è¿”å›diceæŸå¤±
        return 1 - dice


class DiceLossv2(nn.Module):

    def __init__(self, sig=False, eps=1e-8):  # æ·»åŠ  c å‚æ•°
        super(DiceLossv2, self).__init__()
        self.eps = eps
        self.sig = sig

    def forward(self, pred, target):
        if self.sig:
            pred = torch.sigmoid(pred)
        sum_pg = torch.sum(pred * target, dim=(2, 3))
        sum_p2 = torch.sum(pred ** 2, dim=(2, 3))
        sum_g2 = torch.sum(target ** 2, dim=(2, 3))

        numerator = 2 * sum_pg + self.eps  # ç»„åˆé¡¹
        denominator = sum_p2 + sum_g2 + self.eps

        em_global = numerator / denominator
        loss = 1 - em_global.mean()
        return loss


class StableKLLoss(nn.Module):
    def __init__(self, eps=1e-10, reduction='mean'):
        super().__init__()
        self.eps = eps
        self.reduction = reduction
        self.kldiv = nn.KLDivLoss(reduction=reduction)

    def forward(self, pred, gt):
        """
        Args:
            pred (Tensor): é¢„æµ‹å€¼ (B,1,H,W) in [0,1] (ç»è¿‡ Sigmoid)
            gt (Tensor): ç›®æ ‡å€¼ (B,1,H,W) in [0,1]
        Returns:
            loss (Tensor): æ ‡é‡
        """
        # è¾“å…¥æ£€æŸ¥
        assert torch.all(pred >= 0.0) and torch.all(pred <= 1.0), "pred å€¼åŸŸéœ€åœ¨ [0,1] å†…"
        assert torch.all(gt >= 0.0) and torch.all(gt <= 1.0), "gt å€¼åŸŸéœ€åœ¨ [0,1] å†…"

        # å°† pred è½¬æ¢ä¸ºå¯¹æ•°æ¦‚ç‡åˆ†å¸ƒ
        pred = torch.clamp(pred, min=self.eps, max=1.0)  # é¿å… log(0)
        log_pred = torch.log(pred)  # å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒ

        # å°† gt å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒ
        gt = gt / (gt.sum(dim=(1, 2, 3), keepdim=True) + self.eps)  # å½’ä¸€åŒ–å¹¶é¿å…é™¤é›¶

        # è®¡ç®— KL æ•£åº¦æŸå¤±
        loss = self.kldiv(log_pred, gt)
        return loss


class StructureLoss(nn.Module):
    """ SARNet """
    def __init__(self):
        super(StructureLoss, self).__init__()

    def forward(self, pred, mask):
        weit = 1 + 5 * torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)
        wbce = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')
        wbce = (weit * wbce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))

        pred = torch.sigmoid(pred)
        inter = ((pred * mask) * weit).sum(dim=(2, 3))
        union = ((pred + mask) * weit).sum(dim=(2, 3))
        wiou = 1 - (inter + 1) / (union - inter + 1)
        return (wbce + wiou).mean()


class NormalizedLossWeightedSoftAdapt(SoftAdaptBase):
    """Class implementation of the normalized-loss-weighted SoftAdapt variant.

    Attributes:
        beta: A float hyperparameter controlling weight distribution.
            - beta > 0: Assign higher weights to poorly performing components.
            - beta < 0: Assign higher weights to well-performing components.
            - beta = 0: Equal weights (trivial case).
        accuracy_order: Order of finite difference approximation for slopes.
    """
    _FIRST_ORDER_COEFFICIENTS = torch.tensor([-1.0, 1.0], dtype=torch.float32)
    _THIRD_ORDER_COEFFICIENTS = torch.tensor([-11 / 6, 3.0, -3 / 2, 1 / 3], dtype=torch.float32)
    _FIFTH_ORDER_COEFFICIENTS = torch.tensor([-137 / 60, 5.0, -5.0, 10 / 3, -5 / 4, 1 / 5], dtype=torch.float32)

    def __init__(self, beta: float = 0.1, accuracy_order: int = 5, eps=1e-10):
        """Initialize the variant."""
        super().__init__()
        self.beta = beta
        self.accuracy_order = accuracy_order
        self.eps = eps

    def _get_finite_difference(
            self,  # æ·»åŠ  self å‚æ•°
            input_tensor: torch.Tensor,
            order: int = None,
            verbose: bool = True
    ) -> torch.Tensor:
        """PyTorch ç‰ˆæœ¬çš„æœ‰é™å·®åˆ†è®¡ç®—å‡½æ•°."""
        # æ£€æŸ¥è¾“å…¥é•¿åº¦ä¸é˜¶æ•°çš„å…¼å®¹æ€§
        if order is None:
            order = len(input_tensor) - 1
            if verbose:
                print(f"==> æœªæŒ‡å®šæœ‰é™å·®åˆ†çš„é˜¶æ•°ï¼Œè‡ªåŠ¨æ¨æ–­ä¸º {order}ï¼ˆè¾“å…¥é•¿åº¦ {len(input_tensor)}ï¼‰ã€‚")

        if order > len(input_tensor):
            raise ValueError("æœ‰é™å·®åˆ†é˜¶æ•°ä¸èƒ½è¶…è¿‡è¾“å…¥å¼ é‡çš„é•¿åº¦ã€‚")

        # æˆªå–éœ€è¦çš„è¾“å…¥æ•°æ®æ®µ
        if order + 1 < len(input_tensor):
            if verbose:
                print(f"==> è¾“å…¥é•¿åº¦ {len(input_tensor)} è¶…è¿‡é˜¶æ•°+1 ({order + 1})ï¼Œä½¿ç”¨æœ€å {order + 1} ä¸ªå…ƒç´ ã€‚")
            input_tensor = input_tensor[-(order + 1):]

        # åŠ è½½é¢„å®šä¹‰çš„å·®åˆ†ç³»æ•°
        device = input_tensor.device  # ä¿æŒè®¾å¤‡ä¸€è‡´æ€§
        if order % 2 == 0 and order > 5:
            raise ValueError("é˜¶æ•°å¤§äº5æ—¶å¿…é¡»ä¸ºå¶æ•°ã€‚")

        # åŠ è½½é¢„å®šä¹‰çš„å·®åˆ†ç³»æ•°ï¼ˆé€šè¿‡ç±»å±æ€§ï¼‰
        if order == 1:
            constants = self._FIRST_ORDER_COEFFICIENTS.to(device)
        elif order == 3:
            constants = self._THIRD_ORDER_COEFFICIENTS.to(device)
        elif order == 5:
            constants = self._FIFTH_ORDER_COEFFICIENTS.to(device)
        else:
            raise NotImplementedError(f"æš‚ä¸æ”¯æŒé˜¶æ•° {order} çš„å·®åˆ†è®¡ç®—ã€‚")

        # ç¡®ä¿è¾“å…¥å¼ é‡ä¸ç³»æ•°é•¿åº¦åŒ¹é…
        if len(input_tensor) != len(constants):
            raise ValueError(f"è¾“å…¥é•¿åº¦ ({len(input_tensor)}) ä¸ç³»æ•°é•¿åº¦ ({len(constants)}) ä¸åŒ¹é…ã€‚")

        ### TODO
        

    def _compute_rates_of_change(
            self,
            input_tensor: torch.Tensor,
            order: int = 5,
            verbose: bool = True
    ) -> torch.Tensor:
        ### TODO 

    def get_component_weights(self,
                              *loss_component_values: Tuple[torch.Tensor],
                              verbose: bool = True):
        """Compute weights combining normalized slopes and loss magnitudes.

        Args:
            loss_component_values: Historical values of each loss component.
            verbose: Flag to enable warnings.

        Returns:
            torch.Tensor: Normalized-loss-weighted component weights.
        """
        if len(loss_component_values) == 1:
            print("Warning: Trivial weighting with single loss component.")

        device = loss_component_values[0].device  # è·å–è¾“å…¥å¼ é‡çš„è®¾å¤‡
        rates_of_change = []
        average_loss_values = []

        # Step 1: è®¡ç®—å˜åŒ–ç‡å’Œå¹³å‡æŸå¤±å€¼
        for loss_points in loss_component_values:
            loss_points = loss_points.detach()  # ä»…åˆ†ç¦»æ¢¯åº¦ï¼Œä¿æŒè®¾å¤‡ä¸å˜
            computed_rates = self._compute_rates_of_change(loss_points, self.accuracy_order, verbose)
            rates_of_change.append(computed_rates)
            average_loss_values.append(torch.mean(loss_points))

        # åˆå¹¶å¼ é‡ï¼ˆè‡ªåŠ¨ä¿æŒè®¾å¤‡ä¸€è‡´æ€§ï¼‰
        slopes = torch.stack(rates_of_change)
        average_loss_values = torch.stack(average_loss_values)

        # Step 2: å½’ä¸€åŒ–å˜åŒ–ç‡
        ns_i = slopes / (torch.sum(torch.abs(slopes)) + self.eps)
        rates_of_change_normalized = ns_i - torch.max(ns_i)

        # Step 3: è®¡ç®—åŠ æƒ Softmax
        weights = self._softmax(
            input_tensor=rates_of_change_normalized,
            beta=self.beta,
            numerator_weights=average_loss_values
        )

        return weights


class AdpMLL(nn.Module):
    def __init__(self, sftAdpType, device, loss_components:list, supervised_nums=6, update_frequency=6, accuracy_order=5, beta=0.1):
        super(AdpMLL, self).__init__()
        """
        :param sftAdpt:
            Attributes:
                'SoftAdapt': åªå…³æ³¨æ¯ä¸ªæŸå¤±å‡½æ•°çš„å˜åŒ–ç‡
                'NormalizedSoftAdapt': å¯¹æ–œç‡è¿›è¡Œå½’ä¸€åŒ–ï¼Œæ˜¾è‘—å‡å°‘å˜åŒ–ç‡çš„å·®å¼‚ï¼Œä»è€Œä½¿ä¸‰ä¸ªåˆ†é‡ä¹‹é—´çš„æƒé‡åˆ†å¸ƒæ›´åŠ å‡åŒ€
                'LossWeightedSoftAdapt': è€ƒè™‘å˜åŒ–ç‡ï¼Œè¿˜è€ƒè™‘æŸå¤±å‡½æ•°çš„å€¼
                'NormalizedWeightedSoftAdapt': 
        """
        # === å‚æ•°æ ¡éªŒ ===
        assert update_frequency >= accuracy_order + 1, "update_frequencyå¿…é¡»â‰¥accuracy_order+1"
        assert sftAdpType in [SoftAdapt, NormalizedSoftAdapt, LossWeightedSoftAdapt, NormalizedLossWeightedSoftAdapt],  \
            "there isn't this sftAdptï¼[SoftAdapt, NormalizedSoftAdapt, LossWeightedSoftAdapt, NormalizedLossWeightedSoftAdapt]"

        # === æ ¸å¿ƒå‚æ•° ===
        self.loss_components = loss_components
        self.supervised_nums = supervised_nums
        self.update_frequency = update_frequency
        self.accuracy_order = accuracy_order
        self.beta = beta
        self.device = device
        self.training_mode = True
        self.sftAdpType = sftAdpType

        # === è‡ªé€‚åº”æƒé‡åˆå§‹åŒ– ===
        n = len(self.loss_components)   # æŸå¤±ç»„ä»¶çš„æ•°é‡
        self.softadapt_lst = [
            self.sftAdpType(beta=self.beta, accuracy_order=self.accuracy_order)
            for _ in range(self.supervised_nums)
        ]

        ## åˆå§‹åŒ–æƒé‡1
        # self.adapt_weights = [
        #     torch.ones(len(self.loss_components), device=self.device)
        #     for _ in range(self.supervised_nums)
        # ]
        ## åˆå§‹åŒ–æƒé‡1/n
        self.adapt_weights = [
            torch.full((n,), 1.0 / n, device=self.device)
            for _ in range(self.supervised_nums)
        ]
        self.current_tmp_weights = [w.clone() for w in self.adapt_weights]

        # === å†å²æŸå¤±è®°å½•ï¼ˆé•¿åº¦é™åˆ¶ä¸ºaccuracy_order+1ï¼‰ ===
        self.loss_values_history = [
            [deque(maxlen=self.accuracy_order + 1) for _ in range(len(self.loss_components))]
            for _ in range(self.supervised_nums)
        ]
        self.num_iter = 1

    def train(self, mode: bool = True):
        """è®¾ç½®æ¨¡å—ä¸ºè®­ç»ƒæˆ–è¯„ä¼°æ¨¡å¼"""
        self.training_mode = mode

    def eval(self):
        """è®¾ç½®æ¨¡å—ä¸ºè¯„ä¼°æ¨¡å¼"""
        self.train(False)

    def get_current_weights(self):
        """è¿”å›å½“å‰å„å±‚çš„æƒé‡å­—å…¸"""
        weight_dict = {}
        for layer_idx, weights in enumerate(self.adapt_weights):
            for loss_idx, w in enumerate(weights):
                # weight_dict[f"layer{layer_idx}/loss{loss_idx}_w"] = w.item()
                weight_dict[f"layer{layer_idx}_ğ›¼{loss_idx+1}"] = w.item()
        return weight_dict

    def forward(self, pred, gts):
        ## Release after article acceptance

        return total_loss

    def _update_history(self, layer_idx: int, loss_fn: nn.Module, loss_value: torch.Tensor):
        loss_idx = self.loss_components.index(loss_fn)
        self.loss_values_history[layer_idx][loss_idx].append(loss_value.detach().cpu())

    def _update_weights(self, layer_idx):
        # æ£€æŸ¥æ‰€æœ‰æŸå¤±åˆ†é‡çš„å†å²è®°å½•æ˜¯å¦å·²å¡«æ»¡
        # æ£€æŸ¥å†å²æ•°æ®æ˜¯å¦è¶³å¤Ÿ
        all_ready = all(
            len(hist) >= self.accuracy_order + 1
            for hist in self.loss_values_history[layer_idx]
        )
        if not all_ready:
            return

        # æˆªå–æœ€å (accuracy_order+1) ä¸ªç‚¹
        loss_histories = [
            torch.tensor(list(hist)[-self.accuracy_order - 1:])
            for hist in self.loss_values_history[layer_idx]
        ]
        # è®¡ç®—æ–°æƒé‡
        new_weights = self.softadapt_lst[layer_idx].get_component_weights(*loss_histories)
        self.adapt_weights[layer_idx] = new_weights.to(self.device)


bce_loss = nn.BCELoss(size_average=True)    # è¾“å…¥éœ€è¦ç»è¿‡sigmoid
# bce_loss = nn.BCEWithLogitsLoss(size_average=True)
f_loss = FLoss(beta=0.3, log_like=False)
iou_loss = IOULoss(soft=False, size_average=True)
ssim_value = SSIM(window_size=11, size_average=True)
logssim_value = LOGSSIM(window_size=11, size_average=True)
# pixel_loss = nn.MSELoss(reduction='mean')
region_loss = RegionLoss(l=1)
# region_loss = ContrastLoss()
# image_loss = nn.MSELoss(reduction='mean')
# image_loss = DiceLoss()
image_loss = IOULoss(soft=False, size_average=True)
# image_loss = FLoss()



if __name__ == '__main__':
    pil2tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])
    tensor2pil = v2.ToPILImage()
    preprocess = v2.Compose([
        v2.ToImage(),
        v2.ToDtype(torch.float32, scale=True),
        v2.Resize((256, 256)),
        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    img_idx = '0257'
    image_path = f'/home/lsa/Shared/data/ORSSD/test/image/{img_idx}.jpg'
    gt_path = f'/home/lsa/Shared/data/ORSSD/test/gt/{img_idx}.png'

    image = Image.open(image_path).convert('RGB')
    gt = pil2tensor(Image.open(gt_path)).unsqueeze(0)
    gt = transforms.Resize((256,256))(gt)
    img = preprocess(image).unsqueeze(0)  # å› ä¸ºåœ¨batchnormä¼šæ£€æŸ¥ç±»å‹ï¼Œå¿…é¡»æ˜¯4D

    conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)
    img = torch.sigmoid(conv(img))

    region = RegionLoss()
    # l1_loss = L1Loss()
    # l1 = nn.L1Loss(reduction='mean')
    # l2 = nn.MSELoss(reduction='mean')
    # histogramloss = HistogramLoss()
    # cos = CosineSimilarityLoss()
    # kl_loss = nn.KLDivLoss(reduction='mean')  # reduction: 'none'|'batchmean'|'sum'
    # kl = StableKLLoss()
    # adppri = AdaptBIS()
    g_loss = DiceLossv2()
    regionv2 = RegionLoss_v2()

    # print('RegionSSIMLoss', region(img, gt))
    # print('Histogram Loss', histogramloss(img, gt))
    # print('L2_loss', l2(img, gt))
    # print('iou_loss', _iou_loss(img, gt))
    # print('w_iou_loss', _iou_loss(img, gt, alpha=True))
    # print('cos_sim_loss', cos(img, gt))
    # print('kl_loss', kl(img, gt))
    # print('kl_nn', kl_loss(img, gt))
    # print('adppri:', adppri(img, gt))
    print('g_loss', g_loss(img, gt))
    print('regionv1', region(img, gt))
    print('regionv2', regionv2(img, gt))